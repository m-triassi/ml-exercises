{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 432 Assignment 1\n",
    "\n",
    "In this assignment you'll be classifying emojis!\n",
    "\n",
    "<img src=\"img/sample-emojis.png\"/>\n",
    "\n",
    "The assignment is very much like a lab. It is broken into many small and specific steps that build on each other. The main differences are:\n",
    "1. the assignment combines multiple concepts together,\n",
    "3. the assignment will be carefully graded, and\n",
    "2. where <span style=\"color:#080;font-weight:bold\">specified</span>, you must add comments to your code.\n",
    "\n",
    "There are 5 questions: Q1 (20 marks), Q2 (20 marks), Q3 (20 marks), Q4 (10 marks), Q5 (10 marks) and one bonus question Q6 (10 bonus marks).\n",
    "\n",
    "Rules for academic integrity:\n",
    "* Like labs, students are encouraged to ask conceptual questions of TAs and of other students, and can answer each others' conceptual questions.\n",
    "* Unlike labs, students are not allowed to post example code in a public forum, even if the code is wrong; code and pseudocode can only be shared with TAs when requesting help.\n",
    "* Never ask for, or offer, code snippets for the assignment to your fellow students. Doing so is forbidden, and is a major violation of academic integrity, both of the person who shared the code and the person who accepted the code. Violations of academic integrity will be reported to the Dean's Office. Violators risk their academic standing.\n",
    "\n",
    "Advice:\n",
    "* *Invest in plotting.* Plotting is super important for ML and for data sciences generally. So, put in the time to learn how to make plots properly.\n",
    "* *Set random_state whenever applicable.* Some steps of the assignment involve randomness, usually when calling scikit-learn functions. In order to make your assignment reproducible, you must set the *random_state* to some constant (e.g. 0) whenever applicable.\n",
    "* *Save your notebook frequently.* Although Jupyter notebooks are mostly reliable, it is possible to encounter an erroneous state, where the most recent changes cannot be saved to disk by the notebook's own save functionality.\n",
    "\n",
    "**Run the code cell below** to import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                        # for os.path.exists\n",
    "import json                      # for loading metadata\n",
    "import urllib                    # for downloading remote files \n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.tree\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.preprocessing\n",
    "\n",
    "# Matplotlib might complain that a lot of figures are open, but suppress that warning.\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to define some utility functions for fetching data and for processing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(remoteurl: str, localfile: str):\n",
    "    \"\"\"\n",
    "    Download remoteurl to localfile, unless localfile already exists.\n",
    "    Returns the localfile string.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(localfile):\n",
    "        print(\"Downloading %s...\" % localfile)\n",
    "        filename, headers = urllib.request.urlretrieve(remoteurl, localfile)\n",
    "    return localfile\n",
    "\n",
    "def rgba_to_rgb(image):\n",
    "    \"\"\"\n",
    "    Converts image from RGBA format (H,W,4) to RGB format (H,W,3).\n",
    "    Returns the new RGB image.\n",
    "    \"\"\"\n",
    "    assert image.ndim == 3, \"Expected 3-dimensional array\"\n",
    "    assert image.shape[2] == 4, \"Expected 4 colour channels\"\n",
    "    rgb, a = np.split(image, [3], axis=2)  # Split into (H,W,3) and (H,W,1)\n",
    "    return a*rgb + (1-a)                   # Apply alpha blending to get RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q1 &mdash; Download emoji metadata and images [20 marks total]\n",
    "\n",
    "The image data and corresponding metadata that you need for this assignment is available from [github.com/imcal/emoji-data](https://github.com/iamcal/emoji-data), where you can also find a description of the data. The specific files you'll need are only:\n",
    "* *emoji.json*\n",
    "* *sheets-clean/sheet_{vendor}_{size}_clean.png*\n",
    "\n",
    "where *{vendor}* is one of *{apple, facebook, google, twitter}* and *{size}* is the pixel resolution. You'll need emojis from all four vendors, but only the small *16x16* pixel versions (to make training faster). However, do NOT download the files manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q1a &mdash;  Write code to download the files [5 marks]*\n",
    "\n",
    "Use the *download* function defined above to fetch the five files *procedurally*. \n",
    "\n",
    "*Hint:* When you visit a Github URL in your browser, Github normally returns an HTML file for rendering in your web browser. To ask Github for an actual raw file (instead of the web page for displaying that file) you must use special URLs. If you view a file in your web browser https://github.com/iamcal/emoji-data/{path_to_file} then you should use URL https://github.com/iamcal/emoji-data/raw/master/{path_to_file}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Use as many lines as you need.\n",
    "# Feel free to define global variables like EMOJI_SIZE=16 for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q1b &mdash;  Load and inspect the emoji metadata [5 marks]*\n",
    "\n",
    "The emoji metadata is contained in a JSON file, which Python's **[json](https://docs.python.org/3/library/json.html)** module can easily load and parse for you.\n",
    "\n",
    "**Write code** to load the *emoji.json* file, then display the metadata for the first emoji (index 0) so that you can see an example. It should have short name '*hash*'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here. Aim for 2-4 lines.\n",
    "# Keep the metadata in a global variable that you can keep referring to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write code** to find the index of the emoji having short name *'laughing'*, then display its metadata (the *dict* object). Do not use the *sort_order* field of the emoji metadata, it is not relevant to this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here. Aim for 1-5 lines. Keep the index in a global variable for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q1c &mdash;  Load and inspect the emoji image data [10 marks]*\n",
    "\n",
    "The emoji image data is contained in PNG files, which Matplotlib's **[imread](https://matplotlib.org/3.3.2/api/_as_gen/matplotlib.pyplot.imread.html)** function can load as a Numpy array. The image format is RGBA (*red*, *green*, *blue*, *alpha*) where *alpha* determines the opacity of each pixel.\n",
    "\n",
    "**Write code** to load the four emoji sheet images. The list of images should be in order *{apple,facebook,google,twitter}*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answer here. Aim for 1-4 lines. You can define a global variable to hold the list of numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write code** to plot each vendor's sheet image. Generate four separate plots, where the title of each plot should be \"*vendor* (*height*, *width*, *channels*)\" where *height* and *width* are the size of the sheet and *channels* is the number of colour channels. Use the *figsize* argument of Matplotlib's *figure* function to enlarge the figures. The top of your first plot should look like this:\n",
    "\n",
    "<img src=\"img/example-apple-emoji-sheet.png\" width=650/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your answer here. Aim for 4-6 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write code** to generate the same four plots as above, except use Numpy slicing to display only the first 3 rows and 8 columns of the sheet. To ensure you do not crop any emojis, take note of any \"padding\" between the 16x16 emojis in the sheet. Your first plot should look like this, but with the shape numbers (?) and axis ticks filled in:\n",
    "\n",
    "<img src=\"img/example-apple-emoji-sheet-slice.png\" width=650/>\n",
    "\n",
    "(If you see a red question mark like <span style=\"color:red\">?</span> for a vendor, it means they do not provide that particular emoji.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here. Aim for 5-9 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement *get_emoji_image*.** It should extract a 16x16 RGBA emoji image by its style index (0=*apple*, 1=*facebook*, 2=*google*, 3=*twitter*) and emoji index (as they appear in *emoji.json*). Internally, your function may refer to any global variables you have already defined (metadata, images, size, padding). Use the *sheet_x* and *sheet_y* fields of the metadata. Use slicing and avoid for-loops. <span style=\"color:#080;font-weight:bold\">Briefly comment each line of your code.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_emoji_image(style_index, emoji_index):\n",
    "    \"\"\"\n",
    "    Given a vendor style index (apple=0,facebook=1,google=2,twitter=3)\n",
    "    and an emoji index, returns the 16x16 RGBA image as a Numpy array\n",
    "    with shape (16,16,4).\n",
    "    \"\"\"\n",
    "    # Your implementation here. Aim for 5-8 lines (not including comments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implment *plot_emoji_styles*.** Implement the *plot_emoji_styles* function below, using your *get_emoji_image* function as a subroutine. Use *figsize* to control the size of your figure, use Matplotlib's *subplot* and *title* functions along with its **[suptitle](https://matplotlib.org/3.3.2/api/_as_gen/matplotlib.pyplot.suptitle.html)** to create titles that show the emoji index, the emoji short name, and the vendor title above each style, as shown below:\n",
    "\n",
    "<img src=\"img/example-plot-emoji-styles.png\" width=600/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emoji_styles(emoji_index):\n",
    "    \"\"\"Plots all four vendor styles of the given emoji.\"\"\"\n",
    "    # Your implementation here. Aim for 6-8 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run your *plot_emoji_styles*** function to plot the '*laughing*' emoji from **Q1b**. Also plot two other emojis of your choosing. (Except poop. You're not allowed to plot the poop emoji. Don't you dare. No, no wait stop, have some self-respect, don't do it, noooo!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 2-3 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q2 &mdash; Build an emoji data set for machine learning [20 marks total]\n",
    "\n",
    "This question is about converting your list of four raw image sheets into a data set suitable for training with scikit-learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q2a &mdash;  Build a set of inputs $\\boldsymbol{X}$ from the sheet images [5 marks]*\n",
    "\n",
    "**Write code** to build a Numpy array of inputs $\\boldsymbol{X}$ having dtype *float32* and shape $(N,D)$ where $N$ is the total number of emoji images (number of emojis $\\times$ number of vendors) and $D$ is the total number of pixels per emoji (height $\\times$ width $\\times$ channels). Each image should be converted from RGBA (4 channels) to RGB (3 channels) using the *rgba_to_rgb* function defined at the top of this lab. The first rows of $\\boldsymbol{X}$ should all be apple emojis, followed by all facebook emojis, then all google emojis, and finally the last rows should be all twitter emojis. <span style=\"color:#080;font-weight:bold\">Briefly comment each non-trivial line of your code.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here. Aim for 6-10 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q2b &mdash;  Build a set of targets $\\boldsymbol{y}$ from the metadata [5 marks]*\n",
    "\n",
    "Here you'll enumerate the distinct emoji categories, and then build a vector of integer targets $\\boldsymbol{y}$.\n",
    "\n",
    "**Write code** to get a list of distinct emoji categories, using the *category* field from the metadata; ensure that the list of categories is displayed when the code cell below is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answere here. Aim for 2-4 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write code** to build a Numpy array of inputs $\\boldsymbol{y}$ having dtype *int32* and where $y_i \\in \\{0, \\ldots, M-1\\}$ with $M$ being the number of distinct emoji categories. The order of items in $\\boldsymbol{y}$ should match those of $\\boldsymbol{X}$ from **Q2a**. You may use any approach you like, but potentially useful functions include the *list* object's **[index](https://docs.python.org/3/tutorial/datastructures.html)** function and Numpy's **[np.tile](https://numpy.org/doc/stable/reference/generated/numpy.tile.html)** function. <span style=\"color:#080;font-weight:bold\">Briefly comment each non-trivial line of your code.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your answer here. Aim for 3-5 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write code** to demonstrate that, for each $i$ that corresponds to a '*laughing*' emoji (for apple, facebook, google, twitter), its $y_i$ label is set to be the index of the \"Smileys & Emotion\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here. Aim for 1-3 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q2c &mdash;  Split and preprocess the data [10 marks]*\n",
    "\n",
    "**Write code** to randomly split $(\\boldsymbol{X}, \\boldsymbol{y})$ into three parts, with no overlap:\n",
    "1. a *training* set $(\\boldsymbol{X}_\\text{trn}, \\boldsymbol{y}_\\text{trn})$, which you will use to directly train classifiers\n",
    "2. a *validation* set $(\\boldsymbol{X}_\\text{val}, \\boldsymbol{y}_\\text{val})$, which you will use to estimate the best value for a hyperparameter\n",
    "3. a *test* set $(\\boldsymbol{X}_\\text{tst}, \\boldsymbol{y}_\\text{tst})$, which you will use to evaluate final performance of the 'best' hyperparameters\n",
    "\n",
    "The training data should comprise 60% of the full data set. The validation and testing data should each comprise 20% of the original data. Use the **[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)** function and remember to set *random_state* so that your splits (and thereby your conclusions) are reproducible for TAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 2-3 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write code** to normalize the features of $\\boldsymbol{X}_\\text{trn}$, $\\boldsymbol{X}_\\text{val}$, and $\\boldsymbol{X}_\\text{tst}$, using scikit-learn's **[StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)**. Be careful which subset of the data you use for estimating the *StandardScaler* object's *scale_* and *mean_* attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here. Aim for 4-5 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot a scaled and unscaled emoji side-by-side.** Choose a row from $\\boldsymbol{X}_\\text{trn}$ and show how it appears as an RGB image with and without scaling. If Matplotlib complains that values are not in range [0,1], consider using **[np.clip](https://numpy.org/doc/stable/reference/generated/numpy.clip.html)**. Your plot should look like the example below, although the choice of emoji could differ.\n",
    "\n",
    "<img src=\"img/example-scaled-emoji.png\" width=250/>\n",
    "\n",
    "*Hint:* You do not need to know which row in $\\boldsymbol{X}_\\text{trn}$ corresponds to which row in $\\boldsymbol{X}$. Instead you can \"undo\" the scaling on whatever row you pick, using one of the methods provided by *StandardScaler*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here. Aim for 9-12 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q3 &mdash; Train classifiers and identify good hyperparameters [20 marks total]\n",
    "\n",
    "This question has several goals:\n",
    "1. to help you visualize how hyperparameters affect training/validation/test performance.\n",
    "2. to give you a sense for how long certain classifiers take to train or to make predictions.\n",
    "3. to force you to try two useful Python features: (a) passing types as arguments, and (b) argument forwarding.\n",
    "\n",
    "(However, please take the hyperparameter search lab as a better example of how to use scikit-learn for hyperparameter search; this assignment is focused on making things easy to plot and visualize, not on automating the search itself.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q3a &mdash;  Write a function to trains multiple estimators [5 marks]*\n",
    "\n",
    "Throughout **Q3**, you will be training multiple estimators, each with a different hyperparameter setting.\n",
    "\n",
    "**Implement the *train_estimators* utility function.** The idea of this function is to make it easy to train multiple versions of an estimator where a single hyperparameter (specified by *param_name*) takes on a different value (specified by *param_vals*) for each estimator. See the docstring below.\n",
    "\n",
    "*Hint:* For details on how Python argument forwarding works (`**kwargs`), see [this Stack Overflow answer](https://stackoverflow.com/a/36908)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_estimators(X, y, estimator_type, param_name, param_vals, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains multiple instances of `estimator_type` on (X, y) by setting argument\n",
    "    named `param_name` to each value in `param_vals`. Prints a message before\n",
    "    training each instance. Returns the list of trained estimators.\n",
    "    \n",
    "    For example:\n",
    "    \n",
    "       >>> train_estimators(X, y, DecisionTreeClassifier, 'max_depth', [1, 5, 10],\n",
    "                            splitter='random', random_state=0)\n",
    "    \n",
    "       Training DecisionTreeClassifier(max_depth=1, random_state=0, splitter='random')...\n",
    "       Training DecisionTreeClassifier(max_depth=5, random_state=0, splitter='random')...\n",
    "       Training DecisionTreeClassifier(max_depth=10, random_state=0, splitter='random')...\n",
    "\n",
    "       [DecisionTreeClassifier(max_depth=1, random_state=0, splitter='random'),\n",
    "        DecisionTreeClassifier(max_depth=5, random_state=0, splitter='random'),\n",
    "        DecisionTreeClassifier(max_depth=10, random_state=0, splitter='random')] \n",
    "    \"\"\"\n",
    "    # Your implementation here. Aim for 5-10 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to test your implementation of *train_estimators*. (Replace *X_trn* and *y_trn* with whatever you called your training set variables.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_estimators = train_estimators(X_trn, y_trn, sklearn.tree.DecisionTreeClassifier,\n",
    "                                   'max_depth', [1, 5, 10], splitter='random', random_state=0)\n",
    "tree_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q3b &mdash;  Train multiples models, plot their accuracies, and identify good parameters [15 marks]*\n",
    "\n",
    "**Implement the *score_estimators* utility function.** This will be handy for scoring a list of estimators on a particular data set, such as $(\\boldsymbol{X}_\\text{trn}, \\boldsymbol{y}_\\text{trn})$. Use the estimator's own *score* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_estimators(X, y, estimators):\n",
    "    \"\"\"Scores each estimator on (X, y), returning a list of scores.\"\"\"\n",
    "    # Your implementation here. Aim for 1-4 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to test your implementation. It should print three scores per dataset. Each score is a measure of classification accuracy. (Replace *X_trn* and *y_trn* etc with your data set variables.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train:   \", score_estimators(X_trn, y_trn, tree_estimators))\n",
    "print(\"validate:\", score_estimators(X_val, y_val, tree_estimators))\n",
    "print(\"test:    \", score_estimators(X_tst, y_tst, tree_estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to see a demonstration of the `%%time` feature of Jupyter (see [here](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-time)). Note that `%%time` only works if it is the first line in a code cell, before comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000000):  # Burn some CPU cycles in a\n",
    "    pass                  # loop that does nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train multiple *DecisionTreeClassifier*s** on the training set, such that *train_estimators* produces the following output:\n",
    "\n",
    "    Training DecisionTreeClassifier(max_depth=1, random_state=0, splitter='random')...\n",
    "    Training DecisionTreeClassifier(max_depth=5, random_state=0, splitter='random')...\n",
    "    Training DecisionTreeClassifier(max_depth=10, random_state=0, splitter='random')...\n",
    "    Training DecisionTreeClassifier(max_depth=20, random_state=0, splitter='random')...\n",
    "    Training DecisionTreeClassifier(max_depth=50, random_state=0, splitter='random')...\n",
    "    Training DecisionTreeClassifier(max_depth=100, random_state=0, splitter='random')..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Your answer here. Aim for 1-2 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement *plot_estimator_scores*** to visualize the effect of the parameter on accuracy. When applied to the decision tree estimators you trained in the previous cell, the plot should look like below, including legend, colours, marks, and x-axis ticks, but your precise scores may differ depending on how you decided to split the data.\n",
    "\n",
    "<img src=\"img/example-decisiontree-scores-plot.png\" width=375/>\n",
    "\n",
    "*Hint:* You can use your *score_estimators* implementation, but do not do any training.\n",
    "\n",
    "*Hint:* For the title, you can get the object's type from its `__class__` attribute, and you can get the name of its type from the type's `__name__` attribute. Use the first object in *estimators* to determine the name of the classifier type that you're plotting.\n",
    "\n",
    "*Hint:* If your $x$-axis points are not evenly spaced, you can plot each series using any evenly-spaced $x$ values (e.g. via *np.arange*) and then override the x-axis tick labels with whatever you want. See the *labels* argument of Matplotlib's **[xticks](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.xticks.html)** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_estimator_scores(estimators, param_name, param_vals):\n",
    "    \"\"\"\n",
    "    Plots the training, validation, and testing scores of a list of estimators,\n",
    "    where `param_name` and `param_vals` are the same as for `train_estimators`.\n",
    "    The estimator with best validation score will be highlighted with an 'x'.\n",
    "    \"\"\"\n",
    "    # Your implementation here. Use as many lines as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the *DecisionTreeClassifier* scores** by calling your *plot_estimator_scores* function. Your plot should look like the example plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Your code here. Aim for 1 line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train multiple *RandomForestClassifiers*** such that *train_estimators* produces the following output:\n",
    "\n",
    "    Training RandomForestClassifier(max_depth=1, random_state=0)...\n",
    "    Training RandomForestClassifier(max_depth=5, random_state=0)...\n",
    "    Training RandomForestClassifier(max_depth=10, random_state=0)...\n",
    "    Training RandomForestClassifier(max_depth=20, random_state=0)...\n",
    "    Training RandomForestClassifier(max_depth=50, random_state=0)...\n",
    "    Training RandomForestClassifier(max_depth=100, random_state=0)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Your code here. Aim for 1-2 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the *RandomForestClassifier* scores**, again by calling your *plot_estimator_scores* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Your code here. Aim for 1 line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train multiple *LogisticRegression* classifiers** such that *train_estimators* produces the following output:\n",
    "\n",
    "    Training LogisticRegression(C=1e-05, max_iter=10000, random_state=0)...\n",
    "    Training LogisticRegression(C=0.0001, max_iter=10000, random_state=0)...\n",
    "    Training LogisticRegression(C=0.001, max_iter=10000, random_state=0)...\n",
    "    Training LogisticRegression(C=0.01, max_iter=10000, random_state=0)...\n",
    "    Training LogisticRegression(C=0.1, max_iter=10000, random_state=0)...\n",
    "    Training LogisticRegression(max_iter=10000, random_state=0)...\n",
    "    \n",
    "The omission of *C* when the final estimator was printed means it was trained with its default value, which is *C*=1. You can try it yourself:\n",
    "```python\n",
    ">>> LogisticRegression(C=1.01)\n",
    "LogisticRegression(C=1.01)\n",
    "\n",
    ">>> LogisticRegression(C=1.0)\n",
    "LogisticRegression()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Your code here. Aim for 1-2 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the *LogisticRegression* scores**, again by calling your *plot_estimator_scores* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Your code here. Aim for 1 line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train multiple SVM classifiers (*SVC*)** such that *train_estimators* produces the following output:\n",
    "\n",
    "    Training SVC(C=0.01, gamma=0.001, max_iter=10000, random_state=0)...\n",
    "    Training SVC(C=0.1, gamma=0.001, max_iter=10000, random_state=0)...\n",
    "    Training SVC(gamma=0.001, max_iter=10000, random_state=0)...\n",
    "    Training SVC(C=10.0, gamma=0.001, max_iter=10000, random_state=0)...\n",
    "    Training SVC(C=100.0, gamma=0.001, max_iter=10000, random_state=0)...\n",
    "    Training SVC(C=1000.0, gamma=0.001, max_iter=10000, random_state=0)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Your code here. Aim for 1-2 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the *SVM* scores**, again by calling your *plot_estimator_scores* function. Predictions may take several minutes to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Your code here. Aim for 1 line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** Do your plots support the claim that \"validation set performance\" is a good estimate of \"test set performance\" overall? YES/NO then explain below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** Which of your classifiers had the highest test-set performance for its \"best\" configuration (i.e., for the configuration with highest validation-set performance)? Name the classifier and best hyperparameter setting (*max_depth* or *C*)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** Which of your classifiers had the *least over-fitting*, if we measured overfitting as the absolute difference between training-set and testing-set performance? Name the classifier and hyperparameter setting (*max_depth* or *C*)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** Which if your classifiers was slowest to train? Name the classifier."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q4 &mdash; Visualizing mistakes [10 marks total]\n",
    "\n",
    "The goal here is to visualize classification errors, by confusion matrix and by inspecting typical mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4a &mdash;  Plot a confusion matrix for the best estimators [5 marks]*\n",
    "\n",
    "**Write code** to plot a confusion matrix for each of the 'best' estimators in **Q3** when applied to test set $(\\boldsymbol{X}_\\text{tst}, \\boldsymbol{y}_\\text{tst})$. Here, 'best' means best validation score. All estimators are already trained, so you can simply pull out the one best of each type {tree, forest, logistic, svm}. Use **[plot_confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html)**. Your first plot should look like as below, though the numbers may differ.\n",
    "\n",
    "<img src=\"img/example-decisiontree-confusion-matrix.png\" width=\"350\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here. Aim for 7-12 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** What classifier is best at distinguishing between the *Flags* class and the *Objects* class, overall? Name the classifier and justify your choice."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4b &mdash;  Identify specific misclassified examples [5 marks]*\n",
    "\n",
    "In this question, us the \"best performing\" classifier that you named at the end of **Q4a**.\n",
    "\n",
    "**Write code** to identify all \"*Objects* misclassified as *Flags*\" from the test-set and then plot them as images. (The phrase \"*A* misclassified as *B*\" means the prediction was *B* but the true class was *A*.) Your code for identifying the misclassified examples should be vectorized, for example using functions like *np.logical_and* and/or *np.nonzero*. (Remember you might need to \"undo\" the feature normalization like in **Q2c**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here. Aim for 7-12 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** After seeing the failure cases above, can you guess why the estimator is confusing them with *Flags*? Explain in 1-2 sentences."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q5 &mdash; Visualizing feature importances [10 marks total]\n",
    "\n",
    "The goal here is to visualize sensitivity to specific input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q5a &mdash;  Visualize the feature importances of a RandomForestClassifier [5 marks]*\n",
    "\n",
    "**Implement *plot_random_forest_importances*** below. This function should plot the *feature_importances_* attribute of a *RandomForestClassifier* (see scikit-learn docs). For the random forests you trained, there are $16 \\times 16 \\times 3$ features, so to make visualization easy the feature importances should be organized into three separate side-by-side heatmaps: one for each RGB colour channel. When plotting a heatmap, use *cmap*='cool' to choose the colour map. For example, plotting the feature importances of a random forest with *max_depth*=1 should look something like this:\n",
    "\n",
    "<img src=\"img/example-random-forest-feature-importances.png\" width=\"350\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_forest_importances(estimator):\n",
    "    \"\"\"\n",
    "    Plots the feature importances of the given RandomForestClassifier,\n",
    "    arranged as three separate 16x16 heatmaps for (red, green, blue).\n",
    "    \"\"\"\n",
    "    # Your implementation here. Aim for 7-10 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your code** by calling your function to plot the feature importances of first *RandomForestClassifier* that you trained (with *max_depth*=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (1 line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the feature importances** of your 'best' *RandomForestClassifier* instance. The patterns should be more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (1 line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** Why do you think the features near the edge of the image so 'important'? Explain in 1-2 sentences."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q5b &mdash;  Visualize the feature weights of LogisticRegression [5 marks]*\n",
    "\n",
    "This question is essentially the same as **Q5a** except you will extract the per-class weights of a *LogisticRegression* estimator that was trained on emoji images.\n",
    "\n",
    "**Implement *plot_logistic_weights*** so that for each of the 10 categories of emoji it plots three side-by-side images.  Use the *coef_* attribute of *LogisticRegression* to extract the $16 \\times 16 \\times 3$ weights for each category, and then generate a separate heatmap for each RGB channel. Since we want to see clearly which weights are positive or negative, use *cmap*='bwr' when plotting each heatmap. Use *suptitle* to label each group of heatmaps with its category label. Your function should generate $10 \\times 3$ heatmaps total. Below are examples of 2 of the 10 possible rows:\n",
    "\n",
    "<img src=\"img/example-logistic-weights-regularized-animals.png\" width=\"325\"/>\n",
    "<img src=\"img/example-logistic-weights-regularized-smileys.png\" width=\"325\"/>\n",
    "\n",
    "*Hint:* Note that the $i^\\text{th}$ set of weights may not match the order of categories. Use the *classes_* attribute of *LogisticRegression* to recover the category index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_logistic_weights(estimator):\n",
    "    \"\"\"\n",
    "    Plots heatmaps showing the weights of the LogisticRegression estimator,\n",
    "    with a separate plot for each class and for each colour channel.\n",
    "    \"\"\"\n",
    "    assert isinstance(estimator, sklearn.linear_model.LogisticRegression)\n",
    "    # Your implementation here here. Aim for 9-12 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your code** by calling your function to plot the weights of the *LogisticRegression* classifier having *strongest* regularization (the one with *C*=1e-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (1 line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the weights** of your 'best' *LogisticRegression* instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (1 line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** Was your best-performing *LogisiticRegression* classifier also the most interpretable? YES/NO then explain in 2-3 sentences."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q6 &mdash; Generating Python code for a tree  [10 marks BONUS]\n",
    "\n",
    "The goal here is to develop a deeper understanding of scikit-learn's decision tree and data structure, by generating an equivalent Python program, compiling it, and executing it. Most of the question is just learning how things work, and the part you have to do is at the very end.\n",
    "\n",
    "**Run the code cell below**, replacing *X_trn* and *y_trn* with whatever you named your training set variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a tiny tree on a tiny training set of only 4 instances\n",
    "X_tiny = X_trn[:4]\n",
    "y_tiny = y_trn[:4]\n",
    "tiny_tree = sklearn.tree.DecisionTreeClassifier(max_depth=2, random_state=0).fit(X_tiny, y_tiny)\n",
    "\n",
    "# Plot the tree and print the true and predicted labels\n",
    "sklearn.tree.plot_tree(tiny_tree)\n",
    "print(\"true:\", y_tiny)\n",
    "print(\"pred:\", tiny_tree.predict(X_tiny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is meant as a simple easy-to-understand tree, much simpler than the real ones you trained in **Q3**.\n",
    "\n",
    "**Run the code cell below** to see a function that traverses a *DecisionTreeClassifier*'s internal tree data structure and prints a message each time it encounters a split node or a leaf node. Notice how it corresponds to the plotted tree above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(tree):\n",
    "    \"\"\"Prints the structure of a DecisionTreeClassifier.\"\"\"\n",
    "    assert isinstance(tree, sklearn.tree.DecisionTreeClassifier)\n",
    "\n",
    "    # Shorthand for some tree attributes\n",
    "    left = tree.tree_.children_left     # left[i]: index of left  node when i is a split\n",
    "    right = tree.tree_.children_right   # right[i]: index of right node when i is a split\n",
    "    feature = tree.tree_.feature        # feature[i]: index feature to test when i is a split\n",
    "    threshold = tree.tree_.threshold    # threshold[i]: threshold to use when i is a split\n",
    "    votes = tree.tree_.value            # votes[i,j]: number of training examples to reach\n",
    "                                        #             node i while having class index j\n",
    "\n",
    "    def visit_subtree(i, depth):\n",
    "        indent = \"  \"*depth\n",
    "        if left[i] != right[i]:\n",
    "            print(\"%snode %d: split on x[%d] <= %f\" % (indent, i, feature[i], threshold[i]))\n",
    "            visit_subtree(left[i],  depth+1)\n",
    "            visit_subtree(right[i], depth+1)\n",
    "        else:\n",
    "            label = tree.classes_[np.argmax(votes[i])]\n",
    "            print(\"%snode %d: leaf label %d\" % (indent, i, label))\n",
    "            \n",
    "    visit_subtree(0, 0)\n",
    "    \n",
    "print_tree(tiny_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Call *print_tree* on your best *DecisionTreeClassifier*** from **Q3**. (The output will be very long.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (1 line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement the *tree_to_code* function below.** The idea is to transform a *DecisionTreeClassifier* instance into equivalent Python code, where the code is built up as a string. You may copy whatever code you want from *print_tree* as a starting point, but you must <span style=\"color:#080;font-weight:bold\">add a comment for each new line of code</span>.\n",
    "\n",
    "For example, if you called it with the *tiny_tree* from earlier, it might produce a string like below (although not necessarily an identical program, depending on the training set for *tiny_tree*).\n",
    "\n",
    "```\n",
    ">>> print(tree_to_code(tiny_tree))\n",
    "def predict(x):\n",
    "  if x[395] <= -0.642489:\n",
    "    if x[174] <= -0.988780:\n",
    "      return 4\n",
    "    else:\n",
    "      return 7\n",
    "  else:\n",
    "    return 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_code(tree):\n",
    "    \"\"\"\n",
    "    Given a *DecisionTreeClassifier*, returns a string that\n",
    "    defines a Python function that corresponds to how the\n",
    "    decision tree makes predictions. The first line of the\n",
    "    string is:\n",
    "    \n",
    "         \"def predict(x):\\n...\"\n",
    "         \n",
    "    followed by lines of code for the logic of the tree.\n",
    "    \"\"\"\n",
    "    # Your implementation here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to check your implementation. You should see a program equivalent to the tiny decision tree you plotted earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree_to_code(tiny_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to define a utility function called *compile_func*. What this function does is it takes a string containing a single Python function definition, and compiles it, returning a *function* object that can be called to execute the code represented by the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_func(python_code):\n",
    "    \"\"\"\n",
    "    Compiles a string defining a Python function, and returns\n",
    "    a reference to the callable function object that results.\n",
    "    \"\"\"\n",
    "    symbols = {}                             # Dictionary to collect symbols that get defined.\n",
    "    exec(python_code, None, symbols)         # Execute the string as if it were code.\n",
    "    assert len(symbols) == 1, \"Expected python_code to define a function\"\n",
    "    function = next(iter(symbols.values()))  # Get reference to the object that was defined.\n",
    "    assert callable(function), \"Expected python_code to define a function\"\n",
    "    return function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to see a demo of how *compile_func* works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_code = \"\"\"\n",
    "def square(x):\n",
    "    return x**2\n",
    "\"\"\"\n",
    "\n",
    "example_func = compile_func(example_code)\n",
    "print(example_func)\n",
    "\n",
    "for i in range(5):\n",
    "    print(example_func(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write code** to (a) convert your best *DecisionTreeClassifier* to a compiled Python function and (b) assert that the compiled Python function produces the same predictions on the training set $\\boldsymbol{X}_\\text{trn}$. (Note that your Python function expects a 1-dimensional $\\boldsymbol{x}$, whereas *DecisionTreeClassifier* expects a 2-dimensional $\\boldsymbol{X}$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here. Aim for 2-4 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write code to compare the prediction speed** of your *DecisionTreeClassifer* instance versus your pure-Python function. Specifically, you should use `%%time` to report the amount of time that *DecisionTreeClassifer* takes to generate predictions on the training set $\\boldsymbol{X}_\\text{trn}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Your code for timing your best DecisionTreeClassifier here. Aim for 1 line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Your code for timing the Python version here. Aim for 1-2 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** Which version was faster and by how much? What do you think explains this?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('p': conda)",
   "language": "python",
   "name": "python38564bitpcondab3dfc311bb714bf3954fd27834289cd4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
